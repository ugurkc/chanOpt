--SQL Codeblock for Data Cleaning and Feature Implementation
-- Table Modification/Data Cleaning Queries --
--Cleaning By Columns
--SEX:70 values missing, set unspecified
UPDATE mydata
SET sex= 'U'
WHERE sex= ''

--AGE:edits the infeasible data values
UPDATE mydata
SET age = 40
WHERE age > 100 OR age <16
--NEW_CUSTOMER
UPDATE mydata 
SET new_customer = '1' 
WHERE new_customer is null

--SENIORITY:38 rows found to be -9999999, this fixes them to a more realistic value
UPDATE mydata
SET seniority = datediff(MONTH, first_date,date_of_now)
WHERE seniority < 0

--LAST_DATE_PRIMARY: many empty rows, replaces the emptiness with the current date to provide a realistic value
UPDATE mydata
SET last_date_primary = date_of_now
WHERE last_date_primary = ''

--SPOUSE_INDEX:lots of misses
UPDATE mydata
SET spouse_index = 'U'
WHERE spouse_index  = ''

--CHANNEL_TEMP:channel_used, lets see channels according to age and externally store it,
SELECT age, channel_used ,COUNT(channel_used) as counterr  into channeltemp
from mydata
group by age,channel_used
ORDER BY age, counterr desc
--after getting this view, I use an sql trick to add a null value to each column with the highest counterr value per age,
--this allows me to strip all age-channel combinations with the highest frequencies
--how it works is, as we query saying the counter of the 2nd should be > than the 1st channeltemp, a null value will be placed to the row with the highest value because the join table wont have a value existing on it
select channeltemp.*,channeltemp2.counterr as counter2 into freqchannels
from channeltemp
LEFT OUTER JOIN
channeltemp as channeltemp2 on channeltemp.age = channeltemp2.age  AND channeltemp2.counterr > channeltemp.counterr
where channeltemp2.counterr IS NULL
order by channeltemp.age,channeltemp.counterr desc

--modifying the new freqchannels, since we have no need for the counter values. the result is a table with the most frequently used channels for each age group
ALTER TABLE freqchannels
DROP COLUMN counterr, counter2

select * from freqchannels
--we need to null the empty rows to be able to coalesce
UPDATE mydata
SET channel_used = NULL
WHERE channel_used= ''
--now we can use this freqchannels to coalesce the join of our table
--different channels are more popular amongst different age groups, we can sub in the most popular channel per missing row
--CUSTOMER_TYPE:There are values such as 1 and 1.0 in these columns, we should universalize these 
UPDATE mydata
SET customer_type = SUBSTRING(customer_type, 1,1)
WHERE customer_type LIKE '%.%'

--PROVINCE_NAME
select top 1000 REPLACE(province_name,'"','')
FROM mydata,
--this works as intended, lets update
UPDATE mydata
SET province_name = REPLACE(province_name,'"','')
--now we have nulls, lets select those rows to see some correlations
select * from mydata where province_name = ''
--everything seems natural except the province code for these rows are NA and the gross_income values are mostly NULL aswell
-- if we list the provinces in spain,(which are 53), the number count comes up exactly as 53, with the empty name aswell, thus, the only missing value here is Plazas de soberania,but we dont have enough evidence to replace, thus we will set as unknown
DELETE FROM mydata
WHERE province_name = '' --NOT RUN YET,

--Gross income has a showing of 0 NULL values, this is expected as counting ignores nulls, lets count them with the empty province name rows
select * from mydata where gross_income IS NOT NULL AND province_name  = ''
--208 row difference, so small, does not need actioning


--GROSS_INCOME:Average gross income replacement according to regions
SELECT province_name, AVG(TRY_CAST(gross_income AS numeric)) AS regional_average into avginc
from mydata
group by province_name

UPDATE avginc
SET province_name = REPLACE(province_name,'"','')

SELECT *  FROM mydata WHERE gross_income = ''

--so we can coalesce
UPDATE mydata 
SET gross_income = NULL
WHERE gross_income = ''

--SEGMENTATION: Unknowns again
UPDATE mydata
SET segmentation = 'NA'
WHERE segmentation = ''
-- we can again, see that the segmentation rates change at the age limit of 32. people below the age 32 are 03 categorized mostly while 33 and higher are 02 categorized mostly,
-- we can use information to replace the na's

UPDATE mydata
SET segmentation = '03 - UNIVERSITARIO'
WHERE age <= 32 AND segmentation= 'NA'

UPDATE mydata
SET segmentation = '02 - PARTICULARES'
WHERE age >= 33 AND segmentation= 'NA'

SELECT  age, segmentation ,COUNT(channel_used) as counterr
from mydata
group by age,segmentation
ORDER BY age, counterr desc

-- NEW ENTRIES PROBLEM --

SELECT * FROM mydata
where customer_type LIKE ''

--new customer data update
UPDATE mydata
set customer_type='1',customer_relation='A'
where customer_type='' and customer_relation=''

--THE SHIFTING PROBLEM--
--put all shifted rows into a table called shiftTemp
SELECT * into shiftTEMP
FROM mydata
WHERE direct_debit LIKE  '%,%'

SELECT emp_index ,Count(emp_index)
FROM mydata
group by emp_index

--Manual update procedures
UPDATE mydata 
SET province_name = CONCAT(activity_index, ' ', mydata.province_name),
activity_index= gross_income,
gross_income =segmentation,
segmentation = saving_account,
saving_account = guarantees,
guarantees=current_account,
current_account=derivada_account,
derivada_account=payroll_account,
payroll_account = junior_account,
junior_account = mas_particular_account,
mas_particular_account =particular_account,
particular_account = particular_plus_account,
particular_plus_account =short_term_deposits,
short_term_deposits = medium_term_deposits,
medium_term_deposits = long_term_deposits,
long_term_deposits = [e-account],
[e-account]= funds,
funds = mortgage,
mortgage = pensions,
pensions = loans,
loans = taxes,
taxes = credit_card,
credit_card = securities,
securities = home_account,
home_account = payroll,
payroll = pensions_2,
pensions_2 = SUBSTRING(direct_debit,2,1) ,
direct_debit = SUBSTRING(direct_debit,4,1)
FROM mydata where direct_debit LIKE '%,%'


ALTER TABLE mydata 
ALTER COLUMN date_of_now date 

--EMPTY ROWS PROBLEM
DELETE FROM mydata --Executes successfully to take out the empty 27734 or so rows
WHERE age= ' NA' AND emp_index = '' AND residence_index = ''

--Data Aggregation-- 

--Creates the table to take the last values out from into dbms interface
SELECT customer_code,max(date_of_now) as recent into tempDate
	FROM mydata
	GROUP BY customer_code


ALTER TABLE mydata
ALTER COLUMN pensions_2 int

SELECT DISTINCT pensions_2, count(pensions_2)
from mydata
group by pensions_2

UPDATE mydata
SET payroll = '0' WHERE payroll  = 'NA'

UPDATE mydata
SET pensions_2 = '1' WHERE pensions_2 = ' 1' 
UPDATE mydata
SET pensions_2 = '0' WHERE (pensions_2 = ' 0'OR pensions_2 = 'NA' OR pensions_2 = 'A')


--Aggregates the Table--
--Produces the first table "endsantander"
SELECT mydata.customer_code,
MAX(ISNULL(TRY_CAST(mydata.age AS INT),40))AS age, --convert to null
MAX(date_of_now) AS most_recent_date, --Latest appearance
SUM(ISNULL(TRY_CAST(saving_account as int),1)) AS saving_account,
MIN(first_date) AS first_date,
COUNT(mydata.customer_code) AS systemPing,
MAX(recencyTemp.r_emp_index) AS emp_index,
MAX(recencyTemp.r_residence) AS residence,
MAX(recencyTemp.r_sex) AS sex,
MAX(recencyTemp.r_new_customer) AS new_customer,
MAX(recencyTemp.r_seniority + 6) AS seniority, -- yA DA SYSDATE de hesaplanabilir, tam seniority bulmak adına
MAX(recencyTemp.r_customer_type) AS customer_type,
MAX(recencyTemp.r_customer_relation) AS customer_relation,
MAX(recencyTemp.r_residence_index) AS residence_index,
MAX(recencyTemp.r_foreigner_index) AS foreigner_index,
MAX(recencyTemp.r_spouse_index) AS spouse_index, -- majorly null, will not be used
MAX(COALESCE(recencyTemp.r_channel_used,freqchannels.channel_used)) AS recent_channel_used, --channelların kullanılma sayısı feature olabilir
MAX(recencyTemp.r_dead) AS dead,
MAX(recencyTemp.r_address_type) As address_type,
MAX(recencyTemp.r_province_code) AS province_code,
MAX(recencyTemp.r_province_name) AS province_name,
MAX(COALESCE(recencyTemp.r_gross_income,avginc.regional_average)) AS gross_income,
AVG(TRY_CAST(COALESCE(gross_income,avginc.regional_average) as numeric)) AS avgincome,
MAX(recencyTemp.r_segmentation) AS segmentation,
SUM(saving_account) AS saving_account,
SUM(guarantees) AS guarantees,
SUM(current_account) AS current_account,
SUM(derivada_account) AS derivada_account,
SUM(payroll_account) AS payroll_account,
SUM(junior_account) AS junior_account,
SUM(mas_particular_account) AS mas_particular_account,
SUM(particular_account) AS particular_account,
SUM(particular_plus_account) AS particular_plus_account,
SUM(short_term_deposits) AS short_term_deposits,
SUM(medium_term_deposits) AS medium_term_deposits,
SUM(long_term_deposits) AS long_term_deposits,
SUM([e-account]) AS [e-account],
SUM(funds) AS funds,
SUM(mortgage) AS mortgage,
SUM(pensions) AS pensions,
SUM(loans) AS loans,
SUM(taxes) AS taxes,
SUM(credit_card) AS credit_card,
SUM(securities) AS securities,
SUM(home_account) AS home_account,
SUM(payroll) AS payroll,
SUM(pensions_2) AS pensions_2,
SUM(direct_debit) AS direct_debit
FROM mydata
JOIN tempDate
ON tempDate.customer_code =  mydata.customer_code
LEFT OUTER JOIN (SELECT  mydata.customer_code AS r_customer_code,
						 mydata.emp_index AS r_emp_index,
						 mydata.emp_index AS recent_emp_index,
						 mydata.residence AS r_residence,
						 mydata.sex AS r_sex,
						 mydata.new_customer AS r_new_customer,
						 mydata.seniority AS r_seniority,
						 mydata.customer_type AS r_customer_type,
						 mydata.customer_relation AS r_customer_relation,
						 mydata.residence_index AS r_residence_index,
						 mydata.foreigner_index AS r_foreigner_index,
						 mydata.spouse_index AS r_spouse_index,
						 mydata.channel_used AS r_channel_used,
						 mydata.dead AS r_dead,
						 mydata.address_type AS r_address_type,
						 mydata.province_code AS r_province_code,
						 mydata.province_name AS r_province_name,
						 mydata.gross_income AS r_gross_income,
						 mydata.segmentation AS r_segmentation
				FROM mydata,tempDate
				WHERE tempDate.recent = mydata.date_of_now AND mydata.customer_code= tempDate.customer_code ) AS recencyTemp
ON recencyTemp.r_customer_code = mydata.customer_code
JOIN avginc
ON avginc.province_name =  mydata.province_name
JOIN freqchannels
ON freqchannels.age = mydata.age
GROUP BY mydata.customer_code;

--produces the 2nd table with the last periods data--
SELECT customer_code,saving_account,guarantees,current_account,derivada_account,payroll_account,junior_account,mas_particular_account,particular_account,particular_plus_account,short_term_deposits,medium_term_deposits,long_term_deposits,[e-account],funds,mortgage,pensions,loans,taxes,credit_card,securities,home_account,payroll,pensions_2,direct_debit
from mydata
where date_of_now = '2016-05-28'



--emre madazli Data Discovery/Exception Handling

select DISTINCT ISNULL(try_cast(customer_code AS integer),0) AS customer_code from mydata order by customer_code; --customer codeu int e cevirip duplicateleri silme


select emp_index, --emp indexler için
	CASE emp_index 
		when 'A' then 'active' 
		when 'F' then 'filial'
		when '' then 'not emp'
		when'S' then 'not emp'
		when 'B' then 'ex emp'
		when 'N' then 'not emp'
	END AS emp_index
from mydata;




update mydata --residence indexler yanlıştı düzeltmek için
	set residence_index='N'
	where residence='US';
 
update mydata
set residence_index='N'
where residence='FR';
 update mydata
set residence_index='N'
where residence='CO'; 
 
update mydata
set residence_index='S'
where residence='ES'; 
update mydata
set residence_index='N'
where residence=''; 

 select try_cast(age as int) AS age from mydata  -- çalışmıyor ama neden bilmiyorum 
 select avg (age) 
 from mydata 

 


 

 update mydata -- 100  yaşından büyükleri öldürüyorum
 set dead='S'
 where  age> 100 ;
 update mydata 
 set dead= 'unknown'
 where age= 0;
 
 select cast (junior as int) as junior from mydata; 

 select DISTINCT age,junior from mydata;-- 18 yaşından büyük olsada  junior hesabı olabilir mi ?

 select try_cast(seniorty AS int ) from mydata;

 select convert(varchar(50),first_date,126) AS first_date from mydata; --varcharı date e çevirme
 
 select coalesce(first_date,dateadd(month,-(seniorty),getdate())) AS first_date from mydata; --convertlerim çalışmıyor
 select convert(varchar(50),date_of_now,126) AS date_of_now from mydata; -- varcharı date e çevirme









